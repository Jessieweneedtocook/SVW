{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73cec375",
      "metadata": {
        "id": "73cec375"
      },
      "outputs": [],
      "source": [
        "!pip install -q timm opencv-python matplotlib Pillow\n",
        "!pip install datasets\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import timm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_binary_mask(mask_img):\n",
        "    mask_rgb = np.array(mask_img.convert(\"RGB\"))\n",
        "    # Edited areas are black: [0, 0, 0]\n",
        "    binary_mask = np.all(mask_rgb == [0, 0, 0], axis=-1).astype(np.uint8) * 255  # white = edited\n",
        "    return Image.fromarray(binary_mask, mode=\"L\")"
      ],
      "metadata": {
        "id": "fjymy5kVNToI"
      },
      "id": "fjymy5kVNToI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_mask(raw_mask, index, convert_mask=False):\n",
        "    resize_size = (512, 512)\n",
        "\n",
        "    if convert_mask:\n",
        "        mask = convert_to_binary_mask(raw_mask)\n",
        "    else:\n",
        "        mask = raw_mask.convert(\"L\")\n",
        "    mask = mask.resize(resize_size, Image.NEAREST)\n",
        "    mask_path = f\"data/masks/mask_{index:05d}.png\"\n",
        "    mask.save(mask_path)"
      ],
      "metadata": {
        "id": "k8lAuooOIO4H"
      },
      "id": "k8lAuooOIO4H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_img(img, index, convert_mask=False):\n",
        "    resize_size = (512, 512)\n",
        "    img = img.convert(\"RGB\").resize(resize_size, Image.BILINEAR)\n",
        "    img_path = f\"data/images/img_{index:05d}.jpg\"\n",
        "\n",
        "    img.save(img_path)"
      ],
      "metadata": {
        "id": "aZ1BU-OvIQCz"
      },
      "id": "aZ1BU-OvIQCz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_pair(img, raw_mask, index, convert_mask=False):\n",
        "    resize_size = (512, 512)\n",
        "\n",
        "    img = img.convert(\"RGB\").resize(resize_size, Image.BILINEAR)\n",
        "    img_path = f\"data/images/img_{index:05d}.jpg\"\n",
        "    img.save(img_path)\n",
        "\n",
        "    if convert_mask:\n",
        "        mask = convert_to_binary_mask(raw_mask)\n",
        "    else:\n",
        "        mask = raw_mask.convert(\"L\")\n",
        "\n",
        "    mask = mask.resize(resize_size, Image.NEAREST)\n",
        "    mask_path = f\"data/masks/mask_{index:05d}.png\"\n",
        "    mask.save(mask_path)"
      ],
      "metadata": {
        "id": "jmXPLtOrKXgQ"
      },
      "id": "jmXPLtOrKXgQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import islice\n",
        "from datasets import load_dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "dataset = load_dataset(\"BryanW/HumanEdit\", split=\"train\")\n"
      ],
      "metadata": {
        "id": "hTCHV9tz-ALp"
      },
      "id": "hTCHV9tz-ALp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"/content/data/images\", exist_ok=True)  # Create images directory\n",
        "os.makedirs(\"/content/data/masks\", exist_ok=True)   # Create masks directory\n",
        "\n",
        "for i, entry in enumerate(tqdm(dataset)):\n",
        "    save_pair(entry[\"INPUT_IMG\"], entry[\"MASK_IMG\"], i, convert_mask=True)"
      ],
      "metadata": {
        "id": "gJnvaM5oDGiq"
      },
      "id": "gJnvaM5oDGiq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del dataset"
      ],
      "metadata": {
        "id": "DynUTC_TSsa2"
      },
      "id": "DynUTC_TSsa2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_dataset_stream = load_dataset(\"paint-by-inpaint/PIPE\", split=\"train\", streaming=True)\n",
        "pipe_dataset = list(islice(pipe_dataset_stream, 4300))"
      ],
      "metadata": {
        "id": "RIrOwMbUP9E7"
      },
      "id": "RIrOwMbUP9E7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter = len(os.listdir(\"/content/data/images\"))\n",
        "for i, entry in enumerate(tqdm(pipe_dataset)):\n",
        "    save_img(entry[\"target_img\"], counter + i)"
      ],
      "metadata": {
        "id": "YoC5G1XxNvS0"
      },
      "id": "YoC5G1XxNvS0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del pipe_dataset, pipe_dataset_stream"
      ],
      "metadata": {
        "id": "15efK-4VYnl2"
      },
      "id": "15efK-4VYnl2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_dataset_stream = load_dataset(\"paint-by-inpaint/PIPE_Masks\", split=\"train\", streaming=True)\n",
        "mask_dataset = list(islice(mask_dataset_stream, 4300))"
      ],
      "metadata": {
        "id": "cx1AplJtGhX8"
      },
      "id": "cx1AplJtGhX8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter = len(os.listdir(\"/content/data/masks\"))\n",
        "print(counter)\n",
        "for i, entry in enumerate(tqdm(mask_dataset)):\n",
        "    save_mask(entry[\"mask\"], counter + i)"
      ],
      "metadata": {
        "id": "9km4zHDGR5lN"
      },
      "id": "9km4zHDGR5lN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del mask_dataset, mask_dataset_stream"
      ],
      "metadata": {
        "id": "1MelrHkiYrCg"
      },
      "id": "1MelrHkiYrCg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(\"/content/data/images\")))\n",
        "print(len(os.listdir(\"/content/data/masks\")))"
      ],
      "metadata": {
        "id": "-jYxv0yjHRBL"
      },
      "id": "-jYxv0yjHRBL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class StabilityPredictor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = timm.create_model(\"convnext_tiny\", pretrained=True, features_only=True)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(768, 256, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(256, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 1, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)[-1]              # [B, 96, 8, 8]\n",
        "        x = self.decoder(x)                  # [B, 1, 16, 16]\n",
        "        x = F.interpolate(x, size=(256, 256), mode='bilinear', align_corners=False)\n",
        "        return x"
      ],
      "metadata": {
        "id": "7Qhw7cS6-VMk"
      },
      "id": "7Qhw7cS6-VMk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StabilityDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir):\n",
        "        self.image_paths = sorted(os.listdir(image_dir))\n",
        "        self.mask_paths = sorted(os.listdir(mask_dir))\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.image_paths), len(self.mask_paths))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.image_dir, self.image_paths[idx])\n",
        "        mask_path = os.path.join(self.mask_dir, self.mask_paths[idx])\n",
        "\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "\n",
        "        return self.transform(image), self.transform(mask)\n",
        "\n",
        "dataset = StabilityDataset(\"/content/data/images\", \"/content/data/masks\")\n",
        "loader = DataLoader(dataset, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "yB_GdXNFvfpM"
      },
      "id": "yB_GdXNFvfpM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = StabilityPredictor().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "loss_fn = nn.BCELoss(reduction='none')\n",
        "\n",
        "for epoch in range(30):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for imgs, masks in loader:\n",
        "        imgs, masks = imgs.to(device), masks.to(device)\n",
        "        preds = model(imgs)\n",
        "\n",
        "        weights = masks * 12 + 1\n",
        "        loss = loss_fn(preds, masks)\n",
        "        weighted_loss = (loss * weights).mean()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        weighted_loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += weighted_loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss / len(loader):.4f}\")\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/stability_predictor.pth\")"
      ],
      "metadata": {
        "id": "hx2BPFbS-mve"
      },
      "id": "hx2BPFbS-mve",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kgjPOMX0qMf5"
      },
      "id": "kgjPOMX0qMf5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = StabilityPredictor().to(device)\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/stability_predictor.pth\")"
      ],
      "metadata": {
        "id": "Fryo3ibtmVm-"
      },
      "id": "Fryo3ibtmVm-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VBYnweNmmTwZ"
      },
      "id": "VBYnweNmmTwZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "img_path = '/content/img_00952_wm.png'\n",
        "\n",
        "img = Image.open(img_path).convert(\"RGB\")\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "img = transform(img)\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred = model(img.unsqueeze(0).to(device)).squeeze().cpu().numpy()\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "plt.title(\"Input Image\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(pred*10)\n",
        "plt.title(\"Predicted Stability Mask\")\n",
        "plt.colorbar()\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lQnuBtHJ-pva"
      },
      "id": "lQnuBtHJ-pva",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TESTING**"
      ],
      "metadata": {
        "id": "vSkdv7xovJdR"
      },
      "id": "vSkdv7xovJdR"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q timm opencv-python matplotlib Pillow\n",
        "!pip install datasets\n",
        "import torch.nn.functional as F\n",
        "from itertools import islice\n",
        "from datasets import load_dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import timm"
      ],
      "metadata": {
        "id": "tkzzYRxAua6e"
      },
      "id": "tkzzYRxAua6e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nH0NdbGzuXPw"
      },
      "id": "nH0NdbGzuXPw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_mask_test(raw_mask, index, convert_mask=False):\n",
        "    resize_size = (512, 512)\n",
        "\n",
        "    if convert_mask:\n",
        "        mask = convert_to_binary_mask(raw_mask)\n",
        "    else:\n",
        "        mask = raw_mask.convert(\"L\")\n",
        "    mask = mask.resize(resize_size, Image.NEAREST)\n",
        "    mask_path = f\"test/masks/mask_{index:05d}.png\"\n",
        "    mask.save(mask_path)"
      ],
      "metadata": {
        "id": "4HarPJYrrbOV"
      },
      "id": "4HarPJYrrbOV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_img_test(img, index, convert_mask=False):\n",
        "    resize_size = (512, 512)\n",
        "    img = img.convert(\"RGB\").resize(resize_size, Image.BILINEAR)\n",
        "    img_path = f\"test/images/img_{index:05d}.jpg\"\n",
        "\n",
        "    img.save(img_path)"
      ],
      "metadata": {
        "id": "jtdEcXbwrlgp"
      },
      "id": "jtdEcXbwrlgp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"/content/test/images\", exist_ok=True)\n",
        "os.makedirs(\"/content/test/masks\", exist_ok=True)"
      ],
      "metadata": {
        "id": "WFWg6wNIrmd1"
      },
      "id": "WFWg6wNIrmd1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "DL9khL6ToQV0"
      },
      "id": "DL9khL6ToQV0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_dataset_stream = load_dataset(\"paint-by-inpaint/PIPE\", split=\"train\", streaming=True)\n",
        "pipe_dataset_test = list(islice(pipe_dataset_stream, 4300, 5000))"
      ],
      "metadata": {
        "id": "zEMZawKVr6Yr"
      },
      "id": "zEMZawKVr6Yr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "for i, entry in enumerate(tqdm(pipe_dataset_test)):\n",
        "    save_img_test(entry[\"target_img\"], counter + i)"
      ],
      "metadata": {
        "id": "uENzTr8rsFYP"
      },
      "id": "uENzTr8rsFYP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del pipe_dataset_stream, pipe_dataset_test"
      ],
      "metadata": {
        "id": "rajT3zQgsPNJ"
      },
      "id": "rajT3zQgsPNJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_dataset_stream = load_dataset(\"paint-by-inpaint/PIPE_Masks\", split=\"train\", streaming=True)\n",
        "mask_dataset_test = list(islice(mask_dataset_stream, 4300, 5000))"
      ],
      "metadata": {
        "id": "c8w2OiCdsV46"
      },
      "id": "c8w2OiCdsV46",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "print(counter)\n",
        "for i, entry in enumerate(tqdm(mask_dataset_test)):\n",
        "    save_mask_test(entry[\"mask\"], counter + i)"
      ],
      "metadata": {
        "id": "99MdN83lsed8"
      },
      "id": "99MdN83lsed8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del mask_dataset_stream, mask_dataset_test"
      ],
      "metadata": {
        "id": "zhqm7SVwsk2u"
      },
      "id": "zhqm7SVwsk2u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(\"/content/test/images\")))\n",
        "print(len(os.listdir(\"/content/test/masks\")))"
      ],
      "metadata": {
        "id": "OigzYuQUsssE"
      },
      "id": "OigzYuQUsssE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class StabilityPredictor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = timm.create_model(\"convnext_tiny\", pretrained=True, features_only=True)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(768, 256, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(256, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 1, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)[-1]              # [B, 96, 8, 8]\n",
        "        x = self.decoder(x)                  # [B, 1, 16, 16]\n",
        "        x = F.interpolate(x, size=(256, 256), mode='bilinear', align_corners=False)\n",
        "        return x"
      ],
      "metadata": {
        "id": "aW5DxeGVpNQM"
      },
      "id": "aW5DxeGVpNQM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StabilityTestDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir):\n",
        "        self.image_paths = sorted(os.listdir(image_dir))\n",
        "        self.mask_paths = sorted(os.listdir(mask_dir))\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.image_paths), len(self.mask_paths))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(os.path.join(self.image_dir, self.image_paths[idx])).convert(\"RGB\")\n",
        "        mask = Image.open(os.path.join(self.mask_dir, self.mask_paths[idx])).convert(\"L\")\n",
        "        return self.transform(image), self.transform(mask)"
      ],
      "metadata": {
        "id": "QOGgoz0quGCF"
      },
      "id": "QOGgoz0quGCF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# Load model\n",
        "model = StabilityPredictor().to(device)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/stability_predictor.pth\"))\n",
        "model.eval()\n",
        "\n",
        "# Load test data\n",
        "test_dataset = StabilityTestDataset(\"/content/test/images\", \"/content/test/masks\")\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
      ],
      "metadata": {
        "id": "bRBD9F1cuHAu"
      },
      "id": "bRBD9F1cuHAu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "img, mask = test_dataset[416]\n",
        "with torch.no_grad():\n",
        "    pred = model(img.unsqueeze(0).to(device)).squeeze().cpu().numpy()\n",
        "\n",
        "flat = pred.flatten()\n",
        "k = flat.size // 2\n",
        "threshold = torch.topk(torch.tensor(flat), k=k, largest=True).values[-1].item()\n",
        "binary_mask = (pred >= threshold).astype(float)\n",
        "binary_mask = binary_mask.reshape(pred.shape)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "plt.title(\"Input Image\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(mask.squeeze(), cmap=\"gray\")\n",
        "plt.title(\"Ground Truth Mask\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(binary_mask, cmap=\"gray\")\n",
        "plt.title(\"Binary Stability Mask (1=Stable)\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Y3ZfTGhtuNKs"
      },
      "id": "Y3ZfTGhtuNKs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "img_path = '/content/img_00952_wm.png'\n",
        "\n",
        "img = Image.open(img_path).convert(\"RGB\")\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "img = transform(img)\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred = model(img.unsqueeze(0).to(device)).squeeze().cpu().numpy()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "plt.title(\"Input Image\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(pred, cmap=\"gray\")\n",
        "plt.title(\"Binary Stability Mask (1=Stable)\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KLZ6UCOx1QXU"
      },
      "id": "KLZ6UCOx1QXU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_correct_unstable = 0\n",
        "total_edited = 0\n",
        "batches = 0\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for imgs, masks in test_loader:\n",
        "        imgs, masks = imgs.to(device), masks.to(device)\n",
        "        preds = model(imgs)\n",
        "\n",
        "        B, _, H, W = preds.shape\n",
        "        preds_flat = preds.view(B, -1)\n",
        "\n",
        "        k = (H * W) // 2\n",
        "        topk_vals, topk_indices = torch.topk(preds_flat, k=k, largest=True, dim=1)  # highest = most unstable\n",
        "\n",
        "        binary_mask_flat = torch.zeros_like(preds_flat)\n",
        "        binary_mask_flat.scatter_(1, topk_indices, 1.0)\n",
        "\n",
        "        predicted_unstable = binary_mask_flat.view(B, 1, H, W)\n",
        "\n",
        "        correct_unstable = ((predicted_unstable == 1) & (masks == 1)).sum(dim=(1, 2, 3)).float()\n",
        "        total_edited_region = (masks == 1).sum(dim=(1, 2, 3)).float()\n",
        "\n",
        "        total_correct_unstable += correct_unstable.sum()\n",
        "        total_edited += total_edited_region.sum()\n",
        "        batches += 1\n",
        "\n",
        "recall_on_edited = total_correct_unstable / (total_edited + 1e-8)\n",
        "\n",
        "print(f\"% of Edited Region Correctly Predicted as Unstable: {recall_on_edited:.4f}\")\n"
      ],
      "metadata": {
        "id": "SYXoEBNJzEcD"
      },
      "id": "SYXoEBNJzEcD",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}